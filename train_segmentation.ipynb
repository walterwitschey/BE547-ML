{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Import necessary libraries\n",
        "#------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, MaxPooling2D, concatenate, Conv2D, UpSampling2D, SpatialDropout2D, BatchNormalization, Activation\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "from google.cloud import storage\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow\n",
        "import csv\n",
        "import time\n",
        "import tarfile\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow, show\n",
        "import glob\n",
        "from IPython.display import Image, display, clear_output\n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "xgS3teL8bKO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Run to generate credentials - paste the block of code from \n",
        "# \"credentials for BE 547 lab\" into this section\n",
        "#------------------------------------------------------------"
      ],
      "metadata": {
        "id": "hoRE1ipQmhc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Download the data\n",
        "#------------------------------------------------------------\n",
        "client = storage.Client.from_service_account_json(\"auth.json\")\n",
        "bucket = client.get_bucket(\"pennclassdata\")\n",
        "blob = bucket.blob(\"class_data.tar\")\n",
        "blob.download_to_filename(\"class_data.tar\")\n",
        "# Untar it\n",
        "file = tarfile.open('class_data.tar')\n",
        "file.extractall('data')  \n",
        "file.close()\n",
        "print(\"Download complete\")"
      ],
      "metadata": {
        "id": "ABYdJmRPoKay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Load helper functions\n",
        "#------------------------------------------------------------\n",
        "def conv_block_simple(prevlayer, filters, prefix, strides=(1, 1)):\n",
        "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides, name=prefix + \"_conv\")(prevlayer)\n",
        "    conv = BatchNormalization(name=prefix + \"_bn\")(conv)\n",
        "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
        "    return conv\n",
        "\n",
        "def get_simple_unet(input_shape):\n",
        "    img_input = Input((input_shape + (1,)))\n",
        "    conv1 = conv_block_simple(img_input, 32, \"conv1_1\")\n",
        "    conv1 = conv_block_simple(conv1, 32, \"conv1_2\")\n",
        "    pool1 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool1\")(conv1)\n",
        "\n",
        "    conv2 = conv_block_simple(pool1, 64, \"conv2_1\")\n",
        "    conv2 = conv_block_simple(conv2, 64, \"conv2_2\")\n",
        "    pool2 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool2\")(conv2)\n",
        "\n",
        "    conv3 = conv_block_simple(pool2, 128, \"conv3_1\")\n",
        "    conv3 = conv_block_simple(conv3, 128, \"conv3_2\")\n",
        "    pool3 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool3\")(conv3)\n",
        "\n",
        "    conv4 = conv_block_simple(pool3, 256, \"conv4_1\")\n",
        "    conv4 = conv_block_simple(conv4, 256, \"conv4_2\")\n",
        "    conv4 = conv_block_simple(conv4, 256, \"conv4_3\")\n",
        "\n",
        "    up5 = concatenate([UpSampling2D()(conv4), conv3], axis=3)\n",
        "    conv5 = conv_block_simple(up5, 128, \"conv5_1\")\n",
        "    conv5 = conv_block_simple(conv5, 128, \"conv5_2\")\n",
        "\n",
        "    up6 = concatenate([UpSampling2D()(conv5), conv2], axis=3)\n",
        "    conv6 = conv_block_simple(up6, 64, \"conv6_1\")\n",
        "    conv6 = conv_block_simple(conv6, 64, \"conv6_2\")\n",
        "\n",
        "    up7 = concatenate([UpSampling2D()(conv6), conv1], axis=3)\n",
        "    conv7 = conv_block_simple(up7, 32, \"conv7_1\")\n",
        "    conv7 = conv_block_simple(conv7, 32, \"conv7_2\")\n",
        "\n",
        "    conv7 = SpatialDropout2D(0.2)(conv7)\n",
        "\n",
        "    prediction = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(conv7)\n",
        "    model = Model(img_input, prediction)\n",
        "    return model\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)  "
      ],
      "metadata": {
        "id": "B--4byv0ZitG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qpltd65mY6yC"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------\n",
        "# Start training\n",
        "#------------------------------------------------------------\n",
        "smooth = 1\n",
        "    \n",
        "image_datagen = image.ImageDataGenerator(zoom_range=0.1,\n",
        "                                        rotation_range=5,\n",
        "                                        width_shift_range=0.1,\n",
        "                                        height_shift_range=0.1)\n",
        "mask_datagen  = image.ImageDataGenerator(zoom_range=0.1,\n",
        "                                        rotation_range=5,\n",
        "                                        rescale=1./255.,\n",
        "                                        width_shift_range=0.1,\n",
        "                                        height_shift_range=0.1)\n",
        "                                        \n",
        "seed = 1\n",
        "input_shape = (64, 64)\n",
        "output_shape = (64, 64)\n",
        "batch_size = 32\n",
        "\n",
        "image_generator = image_datagen.flow_from_directory(\n",
        "    'data/train/image',\n",
        "    class_mode=None,\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    target_size=output_shape,\n",
        "    color_mode='grayscale')\n",
        "\n",
        "mask_generator = mask_datagen.flow_from_directory(\n",
        "    'data/train/mask',\n",
        "    class_mode=None,\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    target_size=output_shape,\n",
        "    color_mode='grayscale')\n",
        "\n",
        "train_generator = zip(image_generator,mask_generator)\n",
        "\n",
        "seed = 1\n",
        "\n",
        "valid_image_generator = image_datagen.flow_from_directory(\n",
        "    'data/valid/image',\n",
        "    class_mode=None,\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    target_size=output_shape,\n",
        "    color_mode='grayscale')\n",
        "\n",
        "valid_mask_generator = mask_datagen.flow_from_directory(\n",
        "    'data/valid/mask',\n",
        "    class_mode=None,\n",
        "    seed=seed,\n",
        "    shuffle=True,\n",
        "    batch_size=batch_size,\n",
        "    target_size=output_shape,\n",
        "    color_mode='grayscale')\n",
        "\n",
        "valid_generator = zip(valid_image_generator,valid_mask_generator)\n",
        "\n",
        "class WeightsRecorder(tensorflow.keras.callbacks.Callback):\n",
        "    def __init__(self, progressFilePath):\n",
        "        super(WeightsRecorder, self).__init__()\n",
        "        self.progressFilePath = progressFilePath\n",
        "        self.lastTimePoint = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        epoch += 1\n",
        "        training_loss = logs[\"loss\"]\n",
        "        validation_loss = logs[\"val_loss\"]\n",
        "        training_dice = logs[\"dice_coef\"]\n",
        "        validation_dice = logs[\"val_dice_coef\"]\n",
        "        ellapsed = \"%0.1f\" % (time.time() - self.lastTimePoint)\n",
        "        self.lastTimePoint = time.time()\n",
        "        with open(self.progressFilePath, \"a\") as outputFile: \n",
        "            writer = csv.DictWriter(outputFile, lineterminator='\\n', fieldnames=[\"epoch\",\"time(s)\",\"training_loss\",\"validation_loss\", \"training_dice\",\"validation_dice\"])\n",
        "            writer.writerow({\"epoch\": epoch,\"time(s)\": ellapsed, \"training_loss\": training_loss,\"validation_loss\": validation_loss, \"training_dice\": training_dice, \"validation_dice\": validation_dice})\n",
        "\n",
        "\n",
        "outputDirPath = \"training_output\"\n",
        "if not os.path.isdir(outputDirPath):\n",
        "  os.mkdir(outputDirPath)\n",
        "\n",
        "progressFilePath = os.path.join(outputDirPath, \"liver_2D_training_progress.csv\")\n",
        "if not os.path.isfile(progressFilePath):\n",
        "    with open(progressFilePath, \"w\") as outputFile: \n",
        "        writer = csv.DictWriter(outputFile, lineterminator='\\n', fieldnames=[\"epoch\",\"time(s)\",\"training_loss\",\"validation_loss\", \"training_dice\",\"validation_dice\"])\n",
        "        writer.writeheader()\n",
        "recorder = WeightsRecorder(progressFilePath)\n",
        "\n",
        "weight_saver = ModelCheckpoint(os.path.join(outputDirPath, 'liver_model.{epoch:02d}-{val_loss:.2f}-{val_dice_coef:.2f}.h5'),save_best_only=False, save_weights_only=False)\n",
        "callbackList = [recorder, weight_saver]\n",
        "    \n",
        "model = get_simple_unet(input_shape)\n",
        "model.compile(optimizer=Adam(2e-5), loss=tensorflow.keras.losses.binary_crossentropy, metrics=[dice_coef])\n",
        "\n",
        "\n",
        "\n",
        "hist=model.fit_generator(train_generator, validation_data=valid_generator, validation_steps=20, \n",
        "            steps_per_epoch=100, epochs=100, callbacks=callbackList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jraUnGV5Y6yJ"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------\n",
        "# Plot history: cross-entropy\n",
        "#------------------------------------------------------------ \n",
        "plt.plot(hist.history['loss'], label='loss (training data)')\n",
        "plt.plot(hist.history['val_loss'], label='loss (validation data)')\n",
        "plt.ylabel('loss value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Plot history: dice coeff\n",
        "#------------------------------------------------------------ \n",
        "plt.plot(hist.history['dice_coef'], label='dice (training data)')\n",
        "plt.plot(hist.history['val_dice_coef'], label='dice (validation data)')\n",
        "plt.ylabel('dice value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Y-y3Yk4-PZy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Helper functions for visualizing segmentations\n",
        "#------------------------------------------------------------\n",
        "def getBGRWithOverlay(image, mask, alpha=0.5, color=(0,255,0)):\n",
        "    overlay = image.copy()\n",
        "    output = image.copy()\n",
        "    overlay[:,:,0][mask!=0] = color[0]\n",
        "    overlay[:,:,1][mask!=0] = color[1]\n",
        "    overlay[:,:,2][mask!=0] = color[2]\n",
        "    cv2.addWeighted(overlay, alpha, output, 1-alpha, 0, output)\n",
        "    return output\n",
        "def getGrayWithOverlay(image, mask, alpha=0.5, color=(0,255,0)):\n",
        "    image = grayToBGR(image)\n",
        "    return getBGRWithOverlay(image, mask, alpha=alpha, color=color)\n",
        "\n",
        "def grayToBGR(gray):\n",
        "    grayDims = gray.shape\n",
        "    grayBGR = np.zeros((grayDims[0], grayDims[1], 3), np.uint8)\n",
        "    grayBGR[:,:,0] = gray\n",
        "    grayBGR[:,:,1] = gray\n",
        "    grayBGR[:,:,2] = gray\n",
        "    return grayBGR"
      ],
      "metadata": {
        "id": "GVsHGiMFSexv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Load training set for visualization\n",
        "#------------------------------------------------------------\n",
        "imgDirPath_train = \"data/train/image/dummy_class\"\n",
        "imgFilePathList_train = glob.glob(os.path.join(imgDirPath_train, \"*.png\"))\n",
        "imgFilePathList_train = sorted(imgFilePathList_train)\n",
        "\n",
        "maskDirPath_train = \"data/train/mask/dummy_class\"\n",
        "maskFilePathList_train = glob.glob(os.path.join(maskDirPath_train, \"*.png\"))\n",
        "maskFilePathList_train = sorted(maskFilePathList_train)"
      ],
      "metadata": {
        "id": "527TSt_JSUSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Load the weights from an early epoch\n",
        "#------------------------------------------------------------\n",
        "liverWeightsFilePath = \"/content/training_output/liver_model.05-0.26-0.13.h5\"\n",
        "modelLiver = get_simple_unet((256,256))\n",
        "modelLiver.load_weights(liverWeightsFilePath)"
      ],
      "metadata": {
        "id": "XLiVkFaClbAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Show an example segmentation\n",
        "#------------------------------------------------------------\n",
        "img_index = 250\n",
        "imgFilePath = imgFilePathList_train[img_index]\n",
        "img = cv2.imread(imgFilePath,0)\n",
        "img = cv2.resize(img, (256,256))\n",
        "imgOrig = img.copy()\n",
        "img = img[np.newaxis, :, :, np.newaxis]\n",
        "\n",
        "# predicted mask\n",
        "resultLiver = modelLiver.predict(img)[0,:,:,0]\n",
        "predictedmaskLiver = resultLiver > 0.5\n",
        "\n",
        "# ground truth mask\n",
        "maskFilePath = maskFilePathList_train[img_index]\n",
        "mask_orig = cv2.imread(maskFilePath,0)\n",
        "mask_orig = cv2.resize(mask_orig, (256,256))\n",
        "\n",
        "overlay_predicted = getGrayWithOverlay(imgOrig, predictedmaskLiver, alpha=0.5, color=(0,255,0))\n",
        "overlay_groundtruth = getGrayWithOverlay(imgOrig, mask_orig, alpha=0.5, color=(0,255,0))\n",
        "\n",
        "imshow(overlay_predicted)\n",
        "show()\n",
        "imshow(overlay_groundtruth)\n",
        "show()\n",
        "print(imgFilePath)"
      ],
      "metadata": {
        "id": "cSy7E8UvTIZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Load the weights from a late epoch\n",
        "#------------------------------------------------------------\n",
        "liverWeightsFilePath = \"/content/training_output/liver_model.99-0.03-0.62.h5\"\n",
        "modelLiver = get_simple_unet((256,256))\n",
        "modelLiver.load_weights(liverWeightsFilePath)"
      ],
      "metadata": {
        "id": "M44PO4yeYtUS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Show an example segmentation\n",
        "#------------------------------------------------------------\n",
        "img_index = 250\n",
        "imgFilePath = imgFilePathList_train[img_index]\n",
        "img = cv2.imread(imgFilePath,0)\n",
        "img = cv2.resize(img, (256,256))\n",
        "imgOrig = img.copy()\n",
        "img = img[np.newaxis, :, :, np.newaxis]\n",
        "\n",
        "# predicted mask\n",
        "resultLiver = modelLiver.predict(img)[0,:,:,0]\n",
        "predictedmaskLiver = resultLiver > 0.5\n",
        "\n",
        "# ground truth mask\n",
        "maskFilePath = maskFilePathList_train[img_index]\n",
        "mask_orig = cv2.imread(maskFilePath,0)\n",
        "mask_orig = cv2.resize(mask_orig, (256,256))\n",
        "\n",
        "overlay_predicted = getGrayWithOverlay(imgOrig, predictedmaskLiver, alpha=0.5, color=(0,255,0))\n",
        "overlay_groundtruth = getGrayWithOverlay(imgOrig, mask_orig, alpha=0.5, color=(0,255,0))\n",
        "\n",
        "imshow(overlay_predicted)\n",
        "show()\n",
        "imshow(overlay_groundtruth)\n",
        "show()\n",
        "print(imgFilePath)"
      ],
      "metadata": {
        "id": "BtMerhx2Yzue"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}