{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Import necessary libraries\n",
        "#------------------------------------------------------------\n",
        "from tensorflow.keras.layers import Input, MaxPooling2D, concatenate, Conv2D, UpSampling2D, SpatialDropout2D, BatchNormalization, Activation\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
        "from google.cloud import storage\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow\n",
        "import csv\n",
        "import time\n",
        "import tarfile\n",
        "import glob\n",
        "from IPython.display import Image, display, clear_output\n",
        "import cv2\n",
        "from matplotlib.pyplot import imshow, show\n"
      ],
      "metadata": {
        "id": "y8ahiNEJt99U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Run to generate credentials - paste the block of code from \n",
        "# \"credentials for BE 547 lab\" into this section\n",
        "#------------------------------------------------------------\n"
      ],
      "metadata": {
        "id": "VaRDAdNht-tH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Download the data\n",
        "#------------------------------------------------------------\n",
        "client = storage.Client.from_service_account_json(\"auth.json\")\n",
        "bucket = client.get_bucket(\"pennclassdata\")\n",
        "blob = bucket.blob(\"class_data.tar\")\n",
        "blob.download_to_filename(\"class_data.tar\")\n",
        "# Untar it\n",
        "file = tarfile.open('class_data.tar')\n",
        "file.extractall('data')  \n",
        "file.close()\n",
        "# Download the weights\n",
        "blob = bucket.blob(\"liver_run_2_liver_weights.135-0.03-0.84.h5\")\n",
        "blob.download_to_filename(\"liver_run_2_liver_weights.135-0.03-0.84.h5\")\n",
        "blob = bucket.blob(\"spleen_run_2_spleen_model.108-0.09-0.89.h5\")\n",
        "blob.download_to_filename(\"spleen_run_2_spleen_model.108-0.09-0.89.h5\")\n",
        "print(\"Download complete\")\n"
      ],
      "metadata": {
        "id": "XBho1C7-uAD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#------------------------------------------------------------\n",
        "# Load helper functions\n",
        "#------------------------------------------------------------\n",
        "smooth = 1\n",
        "def conv_block_simple(prevlayer, filters, prefix, strides=(1, 1)):\n",
        "    conv = Conv2D(filters, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\", strides=strides, name=prefix + \"_conv\")(prevlayer)\n",
        "    conv = BatchNormalization(name=prefix + \"_bn\")(conv)\n",
        "    conv = Activation('relu', name=prefix + \"_activation\")(conv)\n",
        "    return conv\n",
        "\n",
        "def get_simple_unet(input_shape):\n",
        "    img_input = Input((input_shape + (1,)))\n",
        "    conv1 = conv_block_simple(img_input, 32, \"conv1_1\")\n",
        "    conv1 = conv_block_simple(conv1, 32, \"conv1_2\")\n",
        "    pool1 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool1\")(conv1)\n",
        "\n",
        "    conv2 = conv_block_simple(pool1, 64, \"conv2_1\")\n",
        "    conv2 = conv_block_simple(conv2, 64, \"conv2_2\")\n",
        "    pool2 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool2\")(conv2)\n",
        "\n",
        "    conv3 = conv_block_simple(pool2, 128, \"conv3_1\")\n",
        "    conv3 = conv_block_simple(conv3, 128, \"conv3_2\")\n",
        "    pool3 = MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\", name=\"pool3\")(conv3)\n",
        "\n",
        "    conv4 = conv_block_simple(pool3, 256, \"conv4_1\")\n",
        "    conv4 = conv_block_simple(conv4, 256, \"conv4_2\")\n",
        "    conv4 = conv_block_simple(conv4, 256, \"conv4_3\")\n",
        "\n",
        "    up5 = concatenate([UpSampling2D()(conv4), conv3], axis=3)\n",
        "    conv5 = conv_block_simple(up5, 128, \"conv5_1\")\n",
        "    conv5 = conv_block_simple(conv5, 128, \"conv5_2\")\n",
        "\n",
        "    up6 = concatenate([UpSampling2D()(conv5), conv2], axis=3)\n",
        "    conv6 = conv_block_simple(up6, 64, \"conv6_1\")\n",
        "    conv6 = conv_block_simple(conv6, 64, \"conv6_2\")\n",
        "\n",
        "    up7 = concatenate([UpSampling2D()(conv6), conv1], axis=3)\n",
        "    conv7 = conv_block_simple(up7, 32, \"conv7_1\")\n",
        "    conv7 = conv_block_simple(conv7, 32, \"conv7_2\")\n",
        "\n",
        "    conv7 = SpatialDropout2D(0.2)(conv7)\n",
        "\n",
        "    prediction = Conv2D(1, (1, 1), activation=\"sigmoid\", name=\"prediction\")(conv7)\n",
        "    model = Model(img_input, prediction)\n",
        "    return model\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return -dice_coef(y_true, y_pred)  \n",
        "def getBGRWithOverlay(image, mask, alpha=0.5, color=(0,255,0)):\n",
        "    overlay = image.copy()\n",
        "    output = image.copy()\n",
        "    overlay[:,:,0][mask!=0] = color[0]\n",
        "    overlay[:,:,1][mask!=0] = color[1]\n",
        "    overlay[:,:,2][mask!=0] = color[2]\n",
        "    cv2.addWeighted(overlay, alpha, output, 1-alpha, 0, output)\n",
        "    return output\n",
        "def getGrayWithOverlay(image, mask, alpha=0.5, color=(0,255,0)):\n",
        "    image = grayToBGR(image)\n",
        "    return getBGRWithOverlay(image, mask, alpha=alpha, color=color)\n",
        "\n",
        "def grayToBGR(gray):\n",
        "    grayDims = gray.shape\n",
        "    grayBGR = np.zeros((grayDims[0], grayDims[1], 3), np.uint8)\n",
        "    grayBGR[:,:,0] = gray\n",
        "    grayBGR[:,:,1] = gray\n",
        "    grayBGR[:,:,2] = gray\n",
        "    return grayBGR"
      ],
      "metadata": {
        "id": "Cnsbe4IcuCui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSqpmtorZPk7"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------\n",
        "# Load testing set\n",
        "#------------------------------------------------------------\n",
        "imgDirPath = \"data/test/image/dummy_class\"\n",
        "imgFilePathList = glob.glob(os.path.join(imgDirPath, \"*.png\"))\n",
        "imgFilePathList = sorted(imgFilePathList)\n",
        "\n",
        "print(\"Found %d files to test\" % (len(imgFilePathList)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAPqHlesZPlG"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------\n",
        "# Load weights\n",
        "#------------------------------------------------------------\n",
        "import tensorflow\n",
        "\n",
        "liverWeightsFilePath = \"liver_run_2_liver_weights.135-0.03-0.84.h5\"\n",
        "modelLiver = get_simple_unet((256,256))\n",
        "modelLiver.load_weights(liverWeightsFilePath)\n",
        "\n",
        "spleenWeightsFilePath = \"spleen_run_2_spleen_model.108-0.09-0.89.h5\"\n",
        "modelSpleen = get_simple_unet((256,256))\n",
        "modelSpleen.load_weights(spleenWeightsFilePath)\n",
        "\n",
        "print(\"Finished loading weights\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8URpx-QZPlK"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------\n",
        "# Show example segmentations\n",
        "#------------------------------------------------------------\n",
        "numToShow = 100\n",
        "print(len(imgFilePathList))\n",
        "for index in range(40, min(numToShow, len(imgFilePathList)),2):\n",
        "    imgFilePath = imgFilePathList[index]\n",
        "    img = cv2.imread(imgFilePath,0)\n",
        "    img = cv2.resize(img, (256,256))\n",
        "    imgOrig = img.copy()\n",
        "    img = img[np.newaxis, :, :, np.newaxis]\n",
        "    resultLiver = modelLiver.predict(img)[0,:,:,0]\n",
        "    maskLiver = resultLiver > 0.5\n",
        "    resultSpleen = modelSpleen.predict(img)[0,:,:,0]\n",
        "    maskSpleen = resultSpleen > 0.5\n",
        "    overlay = getGrayWithOverlay(imgOrig, maskLiver, alpha=0.5, color=(0,255,0))\n",
        "    overlay = getBGRWithOverlay(overlay, maskSpleen, alpha=0.5, color=(255,0,0))\n",
        "    imshow(overlay)\n",
        "    show()\n",
        "    print(imgFilePath)\n",
        "    time.sleep(1)\n",
        "    clear_output()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}